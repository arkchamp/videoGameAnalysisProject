{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb5a2cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\arkha\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3febbdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg[binary] in c:\\users\\arkha\\anaconda3\\lib\\site-packages (3.2.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from psycopg[binary]) (4.11.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from psycopg[binary]) (2023.3)\n",
      "Requirement already satisfied: psycopg-binary==3.2.9 in c:\\users\\arkha\\anaconda3\\lib\\site-packages (from psycopg[binary]) (3.2.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg[binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "816db563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import connect\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dbf4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_config = {\n",
    "    \"dbname\": \"videogames_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"admin\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cfce244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games columns: ['title', 'release_date', 'team', 'rating', 'times_listed', 'number_of_reviews', 'genres', 'summary', 'reviews', 'plays', 'playing', 'backlogs', 'wishlist']\n",
      "VGSales columns: ['rank', 'name', 'platform', 'year', 'genre', 'publisher', 'na_sales', 'eu_sales', 'jp_sales', 'other_sales', 'global_sales']\n",
      "Merged columns: ['title', 'release_date', 'team', 'rating', 'times_listed', 'number_of_reviews', 'genres', 'summary', 'reviews', 'plays', 'playing', 'backlogs', 'wishlist', 'rank', 'platform', 'year', 'genre', 'publisher', 'na_sales', 'eu_sales', 'jp_sales', 'other_sales', 'global_sales']\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "games_df = pd.read_csv(\"../cleaned_data/games_cleaned.csv\")\n",
    "vgsales_df = pd.read_csv(\"../cleaned_data/vgsales_cleaned.csv\")\n",
    "merged_df = pd.read_csv(\"../merged_data/merged_data.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "games_df.columns = [col.lower().replace(\" \", \"_\") for col in games_df.columns]\n",
    "vgsales_df.columns = [col.lower().replace(\" \", \"_\") for col in vgsales_df.columns]\n",
    "merged_df.columns = [col.lower().replace(\" \", \"_\") for col in merged_df.columns]\n",
    "\n",
    "# Confirm\n",
    "print(\"Games columns:\", games_df.columns.tolist())\n",
    "print(\"VGSales columns:\", vgsales_df.columns.tolist())\n",
    "print(\"Merged columns:\", merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean merged_df for safe insert\n",
    "\n",
    "# Replace NaNs with None\n",
    "merged_df = merged_df.where(pd.notnull(merged_df), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d00737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for games n sales\n",
    "def insert_dataframe_to_table(df, table_name, conn_config):\n",
    "    with connect(**conn_config) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            # Convert DataFrame rows into list of tuples\n",
    "            rows = df.where(pd.notnull(df), None).values.tolist()\n",
    "            # Generate parameter placeholders\n",
    "            placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "            columns = ', '.join(df.columns)\n",
    "            query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "            for row in rows:\n",
    "                try:\n",
    "                    cur.execute(query, row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting row: {row}\\n{e}\")\n",
    "            conn.commit()\n",
    "    print(f\"Data inserted into {table_name} ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0b05116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into games ✅\n"
     ]
    }
   ],
   "source": [
    "insert_dataframe_to_table(games_df, \"games\", conn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b8848d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into vgsales ✅\n"
     ]
    }
   ],
   "source": [
    "insert_dataframe_to_table(vgsales_df, \"vgsales\", conn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func for merged_data\n",
    "\n",
    "def insert_dataframe_to_table(df, table_name, conn_config):\n",
    "    with connect(**conn_config) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for row in df.itertuples(index=False, name=None):\n",
    "                try:\n",
    "                    # Convert to pure Python types to avoid NAType issues\n",
    "                    row = tuple(None if pd.isna(x) else x for x in row)\n",
    "                    placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "                    columns = ', '.join(df.columns)\n",
    "                    query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "                    cur.execute(query, row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting row: {row}\\n{e}\")\n",
    "            conn.commit()\n",
    "    print(f\"Data inserted into {table_name} ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17f8713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted into merged_data ✅\n"
     ]
    }
   ],
   "source": [
    "insert_dataframe_to_table(merged_df, \"merged_data\", conn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ccc43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
